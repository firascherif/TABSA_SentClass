{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":129},"colab_type":"code","executionInfo":{"elapsed":42541,"status":"ok","timestamp":1590165637522,"user":{"displayName":"Helping Hand","photoUrl":"","userId":"16705135424764131129"},"user_tz":-330},"id":"zBPFB9bu2haM","outputId":"e786bd24-5daf-498c-dc7a-09edcbf825f6"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"colab_type":"code","executionInfo":{"elapsed":3571,"status":"ok","timestamp":1590165641108,"user":{"displayName":"Helping Hand","photoUrl":"","userId":"16705135424764131129"},"user_tz":-330},"id":"ZAdNLq5K20GA","outputId":"00ec217a-d00f-47f6-c105-0d4faec32dc9"},"outputs":[],"source":["cd drive/My Drive/ABSA-DistilBERT"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":625},"colab_type":"code","executionInfo":{"elapsed":13530,"status":"ok","timestamp":1590165607663,"user":{"displayName":"Helping Hand","photoUrl":"","userId":"16705135424764131129"},"user_tz":-330},"id":"6eHg6rB23A07","outputId":"cb4bde8a-9ceb-4eb1-8980-2268d9f28192"},"outputs":[],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"colab_type":"code","executionInfo":{"elapsed":2620546,"status":"ok","timestamp":1590062262336,"user":{"displayName":"Gaurav Bansal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7lL3DXHGteP3tGHVaFfbr4y16RkmYKdkRL74l=s64","userId":"08078359384078211719"},"user_tz":-330},"id":"O-17rYxwgpOU","outputId":"bf8da8b7-66bd-4171-8a71-8d295632af79"},"outputs":[{"name":"stdout","output_type":"stream","text":["05/12/2022 18:24:32 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /Users/admin/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","05/12/2022 18:24:32 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /Users/admin/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","05/12/2022 18:24:32 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","05/12/2022 18:24:32 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /Users/admin/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","05/12/2022 18:24:36 - INFO - transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","05/12/2022 18:24:36 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","05/12/2022 18:47:05 - INFO - __main__ -   Epoch = 1, Batch = 50, Batch loss = 1.002026, Avg loss (per batch) = 0.669897\n","05/12/2022 19:09:36 - INFO - __main__ -   Epoch = 1, Batch = 100, Batch loss = 0.146726, Avg loss (per batch) = 0.627952\n","05/12/2022 19:33:04 - INFO - __main__ -   Epoch = 1, Batch = 150, Batch loss = 1.260997, Avg loss (per batch) = 0.609915\n","05/12/2022 20:07:19 - INFO - __main__ -   Epoch = 1, Batch = 200, Batch loss = 0.070412, Avg loss (per batch) = 0.584946\n","05/12/2022 20:33:12 - INFO - __main__ -   Epoch = 1, Batch = 250, Batch loss = 0.382171, Avg loss (per batch) = 0.580429\n","05/12/2022 20:54:54 - INFO - __main__ -   Epoch = 1, Batch = 300, Batch loss = 0.023103, Avg loss (per batch) = 0.562203\n","05/12/2022 21:24:05 - INFO - __main__ -   Epoch = 1, Batch = 350, Batch loss = 0.881881, Avg loss (per batch) = 0.549384\n","05/12/2022 21:47:35 - INFO - __main__ -   Epoch = 1, Batch = 400, Batch loss = 0.932340, Avg loss (per batch) = 0.537026\n","05/12/2022 22:11:30 - INFO - __main__ -   Epoch = 1, Batch = 450, Batch loss = 0.002151, Avg loss (per batch) = 0.514320\n","05/12/2022 22:39:00 - INFO - __main__ -   Epoch = 1, Batch = 500, Batch loss = 0.189097, Avg loss (per batch) = 0.495009\n","05/12/2022 23:06:48 - INFO - __main__ -   Epoch = 1, Batch = 550, Batch loss = 0.443675, Avg loss (per batch) = 0.493607\n","05/12/2022 23:32:38 - INFO - __main__ -   Epoch = 1, Batch = 600, Batch loss = 0.942312, Avg loss (per batch) = 0.478126\n","05/12/2022 23:55:18 - INFO - __main__ -   Epoch = 1, Batch = 650, Batch loss = 0.109004, Avg loss (per batch) = 0.465785\n","05/13/2022 00:20:55 - INFO - __main__ -   Epoch = 1, Batch = 700, Batch loss = 0.553385, Avg loss (per batch) = 0.455779\n","05/13/2022 00:52:59 - INFO - __main__ -   Epoch = 1, Batch = 750, Batch loss = 0.842737, Avg loss (per batch) = 0.451507\n","05/13/2022 01:25:00 - INFO - __main__ -   Epoch = 1, Batch = 800, Batch loss = 0.002442, Avg loss (per batch) = 0.446541\n","05/13/2022 01:56:50 - INFO - __main__ -   Epoch = 1, Batch = 850, Batch loss = 0.785648, Avg loss (per batch) = 0.439330\n","05/13/2022 02:28:51 - INFO - __main__ -   Epoch = 1, Batch = 900, Batch loss = 0.002541, Avg loss (per batch) = 0.431802\n","05/13/2022 03:00:50 - INFO - __main__ -   Epoch = 1, Batch = 950, Batch loss = 0.043801, Avg loss (per batch) = 0.430233\n","05/13/2022 03:32:30 - INFO - __main__ -   Epoch = 1, Batch = 1000, Batch loss = 0.039448, Avg loss (per batch) = 0.433313\n","05/13/2022 04:04:34 - INFO - __main__ -   Epoch = 1, Batch = 1050, Batch loss = 0.660822, Avg loss (per batch) = 0.441236\n","05/13/2022 04:36:34 - INFO - __main__ -   Epoch = 1, Batch = 1100, Batch loss = 0.015486, Avg loss (per batch) = 0.439345\n","05/13/2022 04:46:28 - INFO - __main__ -   Creating a checkpoint.\n","05/13/2022 06:29:30 - INFO - __main__ -   After 1.000000 epoch, Training loss = 0.441618, Training accuracy = 0.848145\n","05/13/2022 06:54:28 - INFO - __main__ -   Epoch = 2, Batch = 50, Batch loss = 0.571996, Avg loss (per batch) = 0.318077\n","05/13/2022 07:19:24 - INFO - __main__ -   Epoch = 2, Batch = 100, Batch loss = 0.016290, Avg loss (per batch) = 0.318148\n","05/13/2022 07:40:36 - INFO - __main__ -   Epoch = 2, Batch = 150, Batch loss = 0.335969, Avg loss (per batch) = 0.308790\n","05/13/2022 08:01:39 - INFO - __main__ -   Epoch = 2, Batch = 200, Batch loss = 0.002728, Avg loss (per batch) = 0.330050\n","05/13/2022 08:21:43 - INFO - __main__ -   Epoch = 2, Batch = 250, Batch loss = 0.003691, Avg loss (per batch) = 0.308252\n","^C\n"]}],"source":["!python3 bert_sentclass.py --num_train_epochs 10 --max_seq_length 512 --batch_size 8"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":109},"colab_type":"code","executionInfo":{"elapsed":9970,"status":"ok","timestamp":1590062544912,"user":{"displayName":"Gaurav Bansal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7lL3DXHGteP3tGHVaFfbr4y16RkmYKdkRL74l=s64","userId":"08078359384078211719"},"user_tz":-330},"id":"Yib74npgiT01","outputId":"6d138aee-88e9-4a37-9b2f-c7e7d8826eb6"},"outputs":[],"source":["!python evaluation_sentclass.py --pred_data_dir results/test_ep_7.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":109},"colab_type":"code","executionInfo":{"elapsed":10121,"status":"ok","timestamp":1590062626214,"user":{"displayName":"Gaurav Bansal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7lL3DXHGteP3tGHVaFfbr4y16RkmYKdkRL74l=s64","userId":"08078359384078211719"},"user_tz":-330},"id":"pg-yJWk8nWpj","outputId":"8d62e7e2-3323-4e0d-c3d2-bf558bd16433"},"outputs":[],"source":["!python evaluation_sentclass.py --pred_data_dir results/test_ep_8.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"33uR2RG2Q7S4"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"ABSA using bert.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"}},"nbformat":4,"nbformat_minor":0}
